{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "californiaHousing_ML_w_hyperopt.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXYeroG_beiQ",
        "colab_type": "text"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skr_v_vjbqtD",
        "colab_type": "code",
        "outputId": "1155ed05-d105-4ebf-a250-83151e778c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "!pip install 'wrapt<1.11.0,>=1.10.0' --force-reinstall"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-05 13:47:12--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.72.245.79, 52.73.9.93, 34.199.255.1, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.72.245.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16648024 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  15.88M  38.4MB/s    in 0.4s    \n",
            "\n",
            "2019-06-05 13:47:13 (38.4 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [16648024/16648024]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "\u001b[K     |████████████████████████████████| 87.1MB 26.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 440kB 41.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 36.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 21.3MB/s \n",
            "\u001b[?25h  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "Collecting wrapt<1.11.0,>=1.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
            "Successfully built wrapt\n",
            "\u001b[31mERROR: tf-nightly-2-0-preview 2.0.0.dev20190605 has requirement wrapt>=1.11.1, but you'll have wrapt 1.10.11 which is incompatible.\u001b[0m\n",
            "Installing collected packages: wrapt\n",
            "  Found existing installation: wrapt 1.11.1\n",
            "    Uninstalling wrapt-1.11.1:\n",
            "      Successfully uninstalled wrapt-1.11.1\n",
            "Successfully installed wrapt-1.10.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv1x5qu5g4vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./logs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP0TW-BVa-dC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmYFL6JGb0jZ",
        "colab_type": "text"
      },
      "source": [
        "##Fire-up TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FA6OOqgb6nG",
        "colab_type": "text"
      },
      "source": [
        "[Source 1](https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNbT4EEob4y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fmhiHCTcBtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO6RlWTxcCN9",
        "colab_type": "code",
        "outputId": "a984772a-d494-4f7c-e298-ecf41b75359e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://8966bcc7.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb_AFqEzboy-",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBohaUYLcNzx",
        "colab_type": "code",
        "outputId": "b50a355a-63ae-4c21-94f1-25439ebac18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "dataset = fetch_california_housing()\n",
        "\n",
        "df = pd.DataFrame(data= np.c_[dataset.data, 100000*dataset.target],\n",
        "                     columns = dataset.feature_names + ['target'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[df['target']<500000].drop(['target'], axis=1).values,\n",
        "    df[df['target']<500000]['target'],\n",
        "    test_size=0.2)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "I0605 13:48:09.309810 140647850047360 california_housing.py:114] Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfiSC5BNkkJW",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR1Jkvtykrda",
        "colab_type": "text"
      },
      "source": [
        "[Source 2](https://www.tensorflow.org/tensorboard/r2/hyperparameter_tuning_with_hparams)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHjgYW9qk4f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.IntInterval(16, 512))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "    hp.hparams_config(\n",
        "        hparams=[HP_NUM_UNITS, HP_DROPOUT],\n",
        "        metrics=[hp.Metric('MeanAbsoluteError', display_name='MAE')],\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDkWmiJFmTxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_model(run_dir, hparams):\n",
        "    \n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.keras.activations.relu))\n",
        "    model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1))    \n",
        "\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer='Nadam',\n",
        "        loss=tf.metrics.mean_squared_error,\n",
        "        metrics=['MeanAbsoluteError', 'RootMeanSquaredError', 'MeanAbsolutePercentageError'],\n",
        "  )\n",
        "    \n",
        "    \n",
        "    \n",
        "    tbCallBack = tf.keras.callbacks.TensorBoard(log_dir=run_dir, histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_images=False,\n",
        "                         profile_batch=0)\n",
        "    \n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                   min_delta=0,\n",
        "                   patience=10,\n",
        "                   verbose=0,\n",
        "                   mode='auto',\n",
        "                   restore_best_weights=True)\n",
        "    \n",
        "\n",
        "    model.fit(X_train,\n",
        "              y_train.values,\n",
        "              epochs=20000,\n",
        "              verbose=0,\n",
        "              batch_size=512,\n",
        "              validation_split=0.2,\n",
        "              callbacks=[es, tbCallBack, \n",
        "                         hp.KerasCallback('./logs', hparams)]) \n",
        "    \n",
        "    _, mae, rmse, mape = model.evaluate(X_test, y_test.values)\n",
        "    return rmse\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n-LKWxFxCQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "    with tf.summary.create_file_writer(run_dir).as_default():\n",
        "        hp.hparams(hparams)  # record the values used in this trial\n",
        "        accuracy = train_test_model(run_dir, hparams)\n",
        "        tf.summary.scalar('MeanAbsoluteError', accuracy, step=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwWzlg1Uxdgf",
        "colab_type": "code",
        "outputId": "82b84637-2c28-4bb8-a2e1-a4a2c7d6dd84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "!rm -rf ./logs/\n",
        "\n",
        "session_num = 0\n",
        "\n",
        "for num_units in [128, 256, 512]: #HP_NUM_UNITS.domain.values:\n",
        "    for dropout_rate in [0.1, 0.2, 0.3]:  # (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
        "        \n",
        "        hparams = {\n",
        "            HP_NUM_UNITS: num_units,\n",
        "            HP_DROPOUT: dropout_rate,\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        run_name = \"run-%d\" % session_num\n",
        "        print('--- Starting trial: %s' % run_name)\n",
        "        print({h.name: hparams[h] for h in hparams})\n",
        "        run('logs/hparam_tuning/' + run_name, hparams)\n",
        "        session_num += 1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-0\n",
            "{'num_units': 128, 'dropout': 0.1}\n",
            "3930/3930 [==============================] - 0s 39us/sample - loss: 3068386664.1588 - MeanAbsoluteError: 39583.3164 - RootMeanSquaredError: 55393.0195 - MeanAbsolutePercentageError: 24.5171\n",
            "--- Starting trial: run-1\n",
            "{'num_units': 128, 'dropout': 0.2}\n",
            "3930/3930 [==============================] - 0s 58us/sample - loss: 3141566985.0545 - MeanAbsoluteError: 40311.0391 - RootMeanSquaredError: 56049.6797 - MeanAbsolutePercentageError: 24.9697\n",
            "--- Starting trial: run-2\n",
            "{'num_units': 128, 'dropout': 0.3}\n",
            "3930/3930 [==============================] - 0s 38us/sample - loss: 3162471577.0137 - MeanAbsoluteError: 40469.2227 - RootMeanSquaredError: 56235.8633 - MeanAbsolutePercentageError: 25.0746\n",
            "--- Starting trial: run-3\n",
            "{'num_units': 256, 'dropout': 0.1}\n",
            "3930/3930 [==============================] - 0s 40us/sample - loss: 3077869147.1959 - MeanAbsoluteError: 39654.2422 - RootMeanSquaredError: 55478.5430 - MeanAbsolutePercentageError: 24.5897\n",
            "--- Starting trial: run-4\n",
            "{'num_units': 256, 'dropout': 0.2}\n",
            "3930/3930 [==============================] - 0s 39us/sample - loss: 3044585092.8855 - MeanAbsoluteError: 39538.2578 - RootMeanSquaredError: 55177.7656 - MeanAbsolutePercentageError: 24.5783\n",
            "--- Starting trial: run-5\n",
            "{'num_units': 256, 'dropout': 0.3}\n",
            "3930/3930 [==============================] - 0s 40us/sample - loss: 3115586368.6840 - MeanAbsoluteError: 40164.9766 - RootMeanSquaredError: 55817.4414 - MeanAbsolutePercentageError: 24.9285\n",
            "--- Starting trial: run-6\n",
            "{'num_units': 512, 'dropout': 0.1}\n",
            "3930/3930 [==============================] - 0s 43us/sample - loss: 3025690471.7679 - MeanAbsoluteError: 39208.6680 - RootMeanSquaredError: 55006.2773 - MeanAbsolutePercentageError: 24.2601\n",
            "--- Starting trial: run-7\n",
            "{'num_units': 512, 'dropout': 0.2}\n",
            "3930/3930 [==============================] - 0s 40us/sample - loss: 3020551131.9125 - MeanAbsoluteError: 39225.5977 - RootMeanSquaredError: 54959.5430 - MeanAbsolutePercentageError: 24.3116\n",
            "--- Starting trial: run-8\n",
            "{'num_units': 512, 'dropout': 0.3}\n",
            "3930/3930 [==============================] - 0s 41us/sample - loss: 3093115342.3634 - MeanAbsoluteError: 39847.6094 - RootMeanSquaredError: 55615.7812 - MeanAbsolutePercentageError: 24.7066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86vrmlLKxc4D",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}